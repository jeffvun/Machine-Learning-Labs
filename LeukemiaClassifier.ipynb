{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffvun/Machine-Learning-Labs/blob/main/LeukemiaClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frIfD9BH66qV"
      },
      "source": [
        "###**Environment Setup**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3rCVMRazoeB"
      },
      "source": [
        "<h3>  &nbsp;&nbsp;Using Colab Cloud TPU&nbsp;&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"25\"></a></h3>\n",
        "\n",
        "* Click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "* The cell below makes sure you have access to a TPU on Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P6b3uqfzpDI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8di7GxvK798g"
      },
      "source": [
        "The below cell will help install PyTorch, Torchvision, and PyTorch/XLA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OApBOAe1fpH_",
        "outputId": "58dcb457-078e-4d0c-d534-50f4aa1ca15a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-xla==2.0\n",
            "  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl (162.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.9/162.9 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloud-tpu-client==0.10\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision==0.15.2 in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Collecting google-api-python-client==1.8.0 (from cloud-tpu-client==0.10)\n",
            "  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (9.4.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.22.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.1.0)\n",
            "Collecting google-api-core<2dev,>=1.13.0 (from google-api-python-client==1.8.0->cloud-tpu-client==0.10)\n",
            "  Downloading google_api_core-1.34.0-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.16.0)\n",
            "Collecting uritemplate<4dev,>=3.0.0 (from google-api-python-client==1.8.0->cloud-tpu-client==0.10)\n",
            "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (16.0.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torch-xla==2.0) (1.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (2.1.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.60.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.20.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (5.3.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.1.1)\n",
            "Installing collected packages: uritemplate, google-api-core, google-api-python-client, cloud-tpu-client, torch-xla\n",
            "  Attempting uninstall: uritemplate\n",
            "    Found existing installation: uritemplate 4.1.1\n",
            "    Uninstalling uritemplate-4.1.1:\n",
            "      Successfully uninstalled uritemplate-4.1.1\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 2.11.1\n",
            "    Uninstalling google-api-core-2.11.1:\n",
            "      Successfully uninstalled google-api-core-2.11.1\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.84.0\n",
            "    Uninstalling google-api-python-client-2.84.0:\n",
            "      Successfully uninstalled google-api-python-client-2.84.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydrive2 1.6.3 requires google-api-python-client>=1.12.5, but you have google-api-python-client 1.8.0 which is incompatible.\n",
            "earthengine-api 0.1.368 requires google-api-python-client>=1.12.1, but you have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloud-tpu-client-0.10 google-api-core-1.34.0 google-api-python-client-1.8.0 torch-xla-2.0.0.dev20230516+colab uritemplate-3.0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==2.0.1 torchvision==0.15.2 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbupwMF2sH29"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import ImageFolder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61sEq7J0sQtk",
        "outputId": "878cf904-8a97-425e-b129-8cbf7cba9da5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TPU for computation.\n"
          ]
        }
      ],
      "source": [
        "# Choosing gpu or cpu\n",
        "\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(\"Using GPU for computation.\")\n",
        "    elif 'TPU_NAME' in os.environ:\n",
        "        device = xm.xla_device()\n",
        "        print(\"Using TPU for computation.\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"Using CPU for computation.\")\n",
        "    return device\n",
        "\n",
        "device = get_device()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cku8z4NV-BK_"
      },
      "source": [
        "### **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDqf_FOM9_2h"
      },
      "outputs": [],
      "source": [
        "# Defining the path to train and test data folders\n",
        "train_folder = '/content/drive/MyDrive/Others/train'\n",
        "test_folder = '/content/drive/MyDrive/Others/test'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfNxGNko-ei3"
      },
      "outputs": [],
      "source": [
        "# Image transformations for data augmentation and normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(200),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.GaussianBlur((5,9),(0.1,5)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-spyVFQ-hd-",
        "outputId": "ef5cd674-36e9-483e-e7d0-42fffdf1b159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images in training data : 294\n",
            "Images in test data : 97\n"
          ]
        }
      ],
      "source": [
        "# Load the train and test datasets\n",
        "train_dataset = ImageFolder(train_folder, transform=transform)\n",
        "test_dataset = ImageFolder(test_folder, transform=transform)\n",
        "\n",
        "print(f\"Images in training data : {len(train_dataset)}\")\n",
        "print(f\"Images in test data : {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyR_92D-QXnA"
      },
      "source": [
        "### **Preparing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkOKO4zQPgTi",
        "outputId": "f3b3e2b2-c9c6-49db-d9b8-0ddfe9e3245e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 200, 200]) 0\n"
          ]
        }
      ],
      "source": [
        "# Checking the size/structure of tensors we have created\n",
        "\n",
        "img, label = train_dataset[0]\n",
        "print(img.shape, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_RoaIPeQkI4",
        "outputId": "ba1251e6-45c1-4846-fa27-ad5b495c0312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following classes are there : \n",
            " ['apples', 'tomatoes']\n"
          ]
        }
      ],
      "source": [
        "# Checking for the number of classes\n",
        "\n",
        "print(\"The following classes are there : \\n\",train_dataset.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKmpeJEH-lRf"
      },
      "outputs": [],
      "source": [
        "# Spliting the train dataset into train and validation sets\n",
        "\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkbyMTxO-nmT"
      },
      "outputs": [],
      "source": [
        "# Create data loaders for train, validation, and test datasets\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja1bL5EY-rGx"
      },
      "source": [
        "### **Model Building**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCJY_fko-yco"
      },
      "source": [
        "Defining the CNN Architecture: 4 convolutional layers and an outer layer.\n",
        "\n",
        "\n",
        "1.   Convolutional Layer Structure: Is a Convolutional Layer (Input image, Filter) with a ReLU activaton function and a MaxPooling Layer\n",
        "2.   Fully Connected Layer: Has a Linear Activation function that takes on an Input vector of size N (size of the resized images) and gives an output of size K = 2 (2 classes : tomatoes and apples)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE3Hsq4B82A2"
      },
      "outputs": [],
      "source": [
        "# Step 2: Define the CNN model architecture\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        )\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 6 * 6, 512), #size of input has to match nbr colums in matrix 1 (batchsize, inputsize)\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layer(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch[0].to(device), batch[1].to(device)\n",
        "        out = self(images) # Generate predictions\n",
        "        loss = nn.functional.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch[0].to(device), batch[1].to(device)\n",
        "        out = self(images) # Generate predictions\n",
        "        loss = nn.functional.cross_entropy(out, labels) # Calculate loss\n",
        "        acc = accuracy(out, labels) # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean() # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean() # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxOZ_npwH0Bz"
      },
      "source": [
        "### **Hyper-parameter tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFqUj84AV4HZ"
      },
      "outputs": [],
      "source": [
        "# Defining the accuracy, evaluation and fit methods\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "  _, preds = torch.max(outputs, dim=1)\n",
        "  return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "  model.eval()\n",
        "  outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "  return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(),lr)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLWxRQJ-9zJu",
        "outputId": "07d119da-8229-4879-a05a-33204571625d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (conv_layers): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU()\n",
              "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (10): ReLU()\n",
              "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU()\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc_layer): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=18432, out_features=512, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=512, out_features=64, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Linear(in_features=64, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# model summary\n",
        "\n",
        "model = CNNModel().to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8snHXGwDIMO4"
      },
      "source": [
        "### **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qfHplWAj92kG",
        "outputId": "1801bb83-496f-4187-b5bb-20dac95d48e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], train_loss: 0.7262, val_loss: 0.6988, val_acc: 0.3729\n",
            "Epoch [1], train_loss: 0.6945, val_loss: 0.6918, val_acc: 0.6271\n",
            "Epoch [2], train_loss: 0.6920, val_loss: 0.6912, val_acc: 0.6102\n",
            "Epoch [3], train_loss: 0.6889, val_loss: 0.6851, val_acc: 0.6102\n",
            "Epoch [4], train_loss: 0.6789, val_loss: 0.6753, val_acc: 0.6102\n",
            "Epoch [5], train_loss: 0.6633, val_loss: 0.6556, val_acc: 0.6271\n",
            "Epoch [6], train_loss: 0.6395, val_loss: 0.6134, val_acc: 0.6271\n",
            "Epoch [7], train_loss: 0.6039, val_loss: 0.6017, val_acc: 0.7288\n",
            "Epoch [8], train_loss: 0.5810, val_loss: 0.6402, val_acc: 0.5932\n",
            "Epoch [9], train_loss: 0.5466, val_loss: 0.6054, val_acc: 0.6780\n",
            "Epoch [10], train_loss: 0.5436, val_loss: 0.7414, val_acc: 0.5424\n",
            "Epoch [11], train_loss: 0.6060, val_loss: 0.6050, val_acc: 0.7288\n",
            "Epoch [12], train_loss: 0.5656, val_loss: 0.6502, val_acc: 0.6102\n",
            "Epoch [13], train_loss: 0.4996, val_loss: 0.6138, val_acc: 0.6949\n",
            "Epoch [14], train_loss: 0.4725, val_loss: 0.6044, val_acc: 0.7288\n",
            "Epoch [15], train_loss: 0.5008, val_loss: 0.5793, val_acc: 0.7119\n",
            "Epoch [16], train_loss: 0.4422, val_loss: 0.6397, val_acc: 0.6780\n",
            "Epoch [17], train_loss: 0.4561, val_loss: 0.6774, val_acc: 0.6949\n",
            "Epoch [18], train_loss: 0.4409, val_loss: 0.6279, val_acc: 0.7288\n",
            "Epoch [19], train_loss: 0.4684, val_loss: 0.6087, val_acc: 0.6610\n",
            "Epoch [20], train_loss: 0.4458, val_loss: 0.5940, val_acc: 0.7627\n",
            "Epoch [21], train_loss: 0.4871, val_loss: 0.5933, val_acc: 0.7458\n",
            "Epoch [22], train_loss: 0.4715, val_loss: 0.6614, val_acc: 0.6610\n",
            "Epoch [23], train_loss: 0.4365, val_loss: 0.6138, val_acc: 0.7288\n",
            "Epoch [24], train_loss: 0.4465, val_loss: 0.6655, val_acc: 0.6780\n",
            "Epoch [25], train_loss: 0.4531, val_loss: 0.6153, val_acc: 0.6949\n",
            "Epoch [26], train_loss: 0.4347, val_loss: 0.5480, val_acc: 0.7627\n",
            "Epoch [27], train_loss: 0.4042, val_loss: 0.6416, val_acc: 0.6610\n",
            "Epoch [28], train_loss: 0.4168, val_loss: 0.6432, val_acc: 0.7119\n",
            "Epoch [29], train_loss: 0.3859, val_loss: 0.5262, val_acc: 0.7797\n",
            "Epoch [30], train_loss: 0.4771, val_loss: 0.5726, val_acc: 0.7797\n",
            "Epoch [31], train_loss: 0.4554, val_loss: 0.5742, val_acc: 0.7119\n",
            "Epoch [32], train_loss: 0.4036, val_loss: 0.5438, val_acc: 0.7966\n",
            "Epoch [33], train_loss: 0.4075, val_loss: 0.6490, val_acc: 0.7288\n",
            "Epoch [34], train_loss: 0.3743, val_loss: 0.6242, val_acc: 0.6949\n",
            "Epoch [35], train_loss: 0.4038, val_loss: 0.5566, val_acc: 0.7627\n",
            "Epoch [36], train_loss: 0.3921, val_loss: 0.6121, val_acc: 0.7458\n",
            "Epoch [37], train_loss: 0.4050, val_loss: 0.6626, val_acc: 0.6949\n",
            "Epoch [38], train_loss: 0.4079, val_loss: 0.5488, val_acc: 0.7458\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-263158ac0247>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mopt_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-c4f7d829b39d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, lr, model, train_loader, val_loader, opt_func)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-c4f7d829b39d>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-c4f7d829b39d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-a316341373d5>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Generate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Calculate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-c4f7d829b39d>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(outputs, labels)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: From /job:tpu_worker/replica:0/task:0:\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: XLA:TPU compile permanent error. Ran out of memory in memory space hbm. Used 7.58G of 7.48G hbm. Exceeded hbm capacity by 104.41M.\n\nTotal hbm usage >= 8.10G:\n    reserved        530.00M \n    program           2.13G \n    arguments         5.45G \n\nOutput size 6.0K; shares 0B with arguments.\n\nProgram hbm requirement 2.13G:\n    global             4.0K\n    HLO temp          2.13G (84.6% utilization: Unpadded (1.79G) Padded (2.11G), 0.8% fragmentation (17.57M))\n\n  Largest program allocations in hbm:\n\n  1. Size: 625.00M\n     Shape: f32[107,32,200,200]{0,1,3,2:T(8,128)}\n     Unpadded size: 522.46M\n     Extra memory due to padding: 102.54M (1.2x expansion)\n     XLA label: fusion.9.remat5.1.remat = fusion(copy.1443.remat.1.remat2, get-tuple-element.3483, fusion.6783), kind=kOutput, calls=fused_computation.8.clone.clone.clone.clone.clone.1.clone\n     Allocation type: HLO temp\n     ==========================\n\n  2. Size: 625.00M\n     Shape: f32[107,32,200,200]{0,1,3,2:T(8,128)}\n     Unpadded size: 522.46M\n     Extra memory due to padding: 102.54M (1.2x expansion)\n     XLA label: select-and-scatter.389.remat2 = select-and-scatter(fusion.9.remat3, fusion.10880, constant.1375), window={size=1x1x2x2 stride=1x1x2x2}, select=xla_ge_computation.69150, scatter=AddComputation.69154\n     Allocation type: HLO temp\n     ==========================\n\n  3. Size: 625.00M\n     Shape: f32[107,32,200,200]{0,1,3,2:T(8,128)}\n     Unpadded size: 522.46M\n     Extra memory due to padding: 102.54M (1.2x expansion)\n     XLA label: fusion.9.remat3 = fusion(copy.1443.remat.1.remat.1.remat, get-tuple-element.3483, fusion.6783), kind=kOutput, calls=fused_computation.8.clone.clone.clone\n     Allocation type: HLO temp\n     ==========================\n\n  4. Size: 156.25M\n     Shape: f32[107,32,100,100]{0,1,3,2:T(8,128)}\n     Unpadded size: 130.62M\n     Extra memory due to padding: 25.63M (1.2x expansion)\n     XLA label: fusion.10880 = fusion(get-tuple-element.3485, select-and-scatter.388, fusion.255.remat4), kind=kOutput, calls=fused_computation.10085\n     Allocation type: HLO temp\n     ==========================\n\n  5. Size: 36.00M\n     Shape: f32[512,18432]{1,0:T(8,128)}\n     Unpadded size: 36.00M\n     XLA label: fusion.2199 = fusion(fusion.2202, copy.1562, copy.1563, copy.1557, ...(+9)), kind=kOutput, calls=fused_computation.1955\n     Allocation type: HLO temp\n     ==========================\n\n  6. Size: 36.00M\n     Shape: f32[512,18432]{1,0:T(8,128)}\n     Unpadded size: 36.00M\n     XLA label: fusion.2199 = fusion(fusion.2202, copy.1562, copy.1563, copy.1557, ...(+9)), kind=kOutput, calls=fused_computation.1955\n     Allocation type: HLO temp\n     ==========================\n\n  7. Size: 36.00M\n     Shape: f32[512,18432]{1,0:T(8,128)}\n     Unpadded size: 36.00M\n     XLA label: fusion.2199 = fusion(fusion.2202, copy.1562, copy.1563, copy.1557, ...(+9)), kind=kOutput, calls=fused_computation.1955\n     Allocation type: HLO temp\n     ==========================\n\n  8. Size: 4.50M\n     Shape: f32[512,256,3,3]{0,1,3,2:T(8,128)}\n     Unpadded size: 4.50M\n     XLA label: fusion.3909 = fusion(get-tuple-element.3491, copy.1562, copy.1563, copy.1557, ...(+10)), kind=kOutput, calls=fused_computation.3501\n     Allocation type: HLO temp\n     ==========================\n\n  9. Size: 4.50M\n     Shape: f32[512,256,3,3]{0,1,3,2:T(8,128)}\n     Unpadded size: 4.50M\n     XLA label: fusion.3909 = fusion(get-tuple-element.3491, copy.1562, copy.1563, copy.1557, ...(+10)), kind=kOutput, calls=fused_computation.3501\n     Allocation type: HLO temp\n     ==========================\n\n  10. Size: 4.50M\n     Shape: f32[512,256,3,3]{0,1,3,2:T(8,128)}\n     Unpadded size: 4.50M\n     XLA label: fusion.3909 = fusion(get-tuple-element.3491, copy.1562, copy.1563, copy.1557, ...(+10)), kind=kOutput, calls=fused_computation.3501\n     Allocation type: HLO temp\n     ==========================\n\n  11. Size: 1.12M\n     Shape: f32[256,128,3,3]{0,1,3,2:T(8,128)}\n     Unpadded size: 1.12M\n     XLA label: fusion.4169 = fusion(get-tuple-element.3489, copy.1562, copy.1563, copy.1557, ...(+10)), kind=kOutput, calls=fused_computation.3759\n     Allocation type: HLO temp\n     ==========================\n\n  12. Size: 1.12M\n     Shape: f32[256,128,3,3]{0,1,3,2:T(8,128)}\n     Unpadded size: 1.12M\n     XLA label: fusion.4169 = fusion(get-tuple-element.3489, copy.1562, copy.1563, copy.1557, ...(+10)), kind=kOutput, calls=fused_computation.3759\n     Allocation type: HLO temp\n     ==========================\n\n  13. Size: 1.12M\n     Shape: f32[256,128,3,3]{0,1,3,2:T(8,128)}\n     Unpadded size: 1.12M\n     XLA label: fusion.4169 = fusion(get-tuple-element.3489, copy.1562, copy.1563, copy.1557, ...(+10)), kind=kOutput, calls=fused_computation.3759\n     Allocation type: HLO temp\n     ==========================\n\n  14. Size: 288.0K\n     Shape: f32[128,64,3,3]{0,1,3,2:T(8,128)}\n     Unpadded size: 288.0K\n     XLA label: fusion.4429 = fusion(get-tuple-element.3487, copy.1562, copy.1563, copy.1557, ...(+10)), kind=kOutput, calls=fused_computation.4017\n     Allocation type: HLO temp\n     ==========================\n\n  15. Size: 288.0K\n     Shape: f32[128,64,3,3]{0,1,3,2:T(8,128)}\n     Unpadded size: 288.0K\n     XLA label: fusion.4429 = fusion(get-tuple-element.3487, copy.1562, copy.1563, copy.1557, ...(+10)), kind=kOutput, calls=fused_computation.4017\n     Allocation type: HLO temp\n     ==========================\n\n  16. Size: 288.0K\n     Shape: f32[128,64,3,3]{0,1,3,2:T(8,128)}\n     Unpadded size: 288.0K\n     XLA label: fusion.4429 = fusion(get-tuple-element.3487, copy.1562, copy.1563, copy.1557, ...(+10)), kind=kOutput, calls=fused_computation.4017\n     Allocation type: HLO temp\n     ==========================\n\n  17. Size: 224.0K\n     Shape: f32[107,512]{1,0:T(8,128)}\n     Unpadded size: 214.0K\n     Extra memory due to padding: 10.0K (1.0x expansion)\n     XLA label: fusion.4788 = fusion(reshape.68539, fusion.2202, fusion.6125), kind=kOutput, calls=fused_computation.4376\n     Allocation type: HLO temp\n     ==========================\n\n  18. Size: 144.0K\n     Shape: f32[64,32,3,3]{0,1,3,2:T(8,128)}\n     Unpadded size: 72.0K\n     Extra memory due to padding: 72.0K (2.0x expansion)\n     XLA label: fusion.4927 = fusion(get-tuple-element.3485, copy.1562, copy.1563, copy.1557, ...(+10)), kind=kOutput, calls=fused_computation.4515\n     Allocation type: HLO temp\n     ==========================\n\n  19. Size: 144.0K\n     Shape: f32[64,32,3,3]{0,1,3,2:T(8,128)}\n     Unpadded size: 72.0K\n     Extra memory due to padding: 72.0K (2.0x expansion)\n     XLA label: fusion.4927 = fusion(get-tuple-element.3485, copy.1562, copy.1563, copy.1557, ...(+10)), kind=kOutput, calls=fused_computation.4515\n     Allocation type: HLO temp\n     ==========================\n\n  20. Size: 144.0K\n     Shape: f32[64,32,3,3]{0,1,3,2:T(8,128)}\n     Unpadded size: 72.0K\n     Extra memory due to padding: 72.0K (2.0x expansion)\n     XLA label: fusion.4927 = fusion(get-tuple-element.3485, copy.1562, copy.1563, copy.1557, ...(+10)), kind=kOutput, calls=fused_computation.4515\n     Allocation type: HLO temp\n     ==========================\n\n\n\t [[{{node XRTCompile}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: XLA:TPU compile permanent error. Ran out of memory in memory space hbm. Used 7.58G of 7.48G hbm. Exceeded hbm capacity by 104.41M.\n\nTotal hbm usage >= 8.10G:\n    reserved        530.00M \n    program           2.13G \n    arguments         5.45G \n\nOutput size 6.0K; shares 0B with arguments.\n\nProgram hbm requirement 2.13G:\n    global             4.0K\n    HLO temp          2.13G (84.6% utilization: Unpadded (1.79G) Padded (2.11G), 0.8% fragmentation (17.57M))\n\n  Largest program allocations in hbm:\n\n  1. Size: 625.00M\n     Shape: f32[107,32,200,200]{0,1,3,2:T(8,128)}\n     Unpadded size: 522.46M\n     Extra memory due to padding: 102.54M (1.2x expansion)\n     XLA label: fusion.9.remat5.1.remat = fusion(copy.1443.remat.1.remat2, get-tuple-element.3483, fusion.6783), kind=kOutput, calls=fus"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "\n",
        "num_epochs = 50\n",
        "lr =0.001\n",
        "opt_func = optim.Adam\n",
        "\n",
        "history = fit(num_epochs, lr, model, train_loader, val_loader, opt_func)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urEk2wesZl1F"
      },
      "source": [
        "### **Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82IKVnaw95E2"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(history):\n",
        "    print(\"Plot the history of accuracies\")\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "\n",
        "\n",
        "plot_accuracies(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIUQ5f0p1mMx"
      },
      "outputs": [],
      "source": [
        "def plot_losses(history):\n",
        "    print(\"Plot the losses in each epoch\")\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "\n",
        "plot_losses(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eGs45DYDhWo"
      },
      "outputs": [],
      "source": [
        "# Evaluate model on test data\n",
        "\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {(100 * correct / total):.2f}%\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "10XY4_tE_pAKprTo6mdivbRh89ff0jtgo",
      "authorship_tag": "ABX9TyMbixIjePLNEensUJQYHdXY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}