{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMHf4g3Rblh0Rfwhh1F451",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffvun/Machine-Learning-Labs/blob/main/Bayesian_Stats_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages('rstan')\n",
        "install.packages('tidyverse')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiTjvNOR68bQ",
        "outputId": "046c75a5-691f-4f35-8019-2696d4ae64ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘checkmate’, ‘matrixStats’, ‘StanHeaders’, ‘inline’, ‘gridExtra’, ‘Rcpp’, ‘RcppParallel’, ‘loo’, ‘QuickJSR’, ‘RcppEigen’, ‘BH’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "onR-S9u0wthV"
      },
      "outputs": [],
      "source": [
        "# Load Required Packages\n",
        "library(rstan)\n",
        "library(tidyverse)\n",
        "library(haven)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Import\n",
        "hospital_data <- read_dta(\"/content/hospital_at_home.dta\")\n",
        "summary(hospital_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "n26r6iuF55e7",
        "outputId": "c49e41b8-2f2c-426a-9745-aec6f27f8040"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      age            age_z              sex          intervention   \n",
              " Min.   :15.91   Min.   :-3.5455   Min.   :0.0000   Min.   :0.0000  \n",
              " 1st Qu.:57.25   1st Qu.:-0.7053   1st Qu.:0.0000   1st Qu.:0.0000  \n",
              " Median :69.80   Median : 0.1565   Median :0.0000   Median :0.0000  \n",
              " Mean   :67.52   Mean   : 0.0000   Mean   :0.4815   Mean   :0.3968  \n",
              " 3rd Qu.:78.50   3rd Qu.: 0.7547   3rd Qu.:1.0000   3rd Qu.:1.0000  \n",
              " Max.   :95.30   Max.   : 1.9085   Max.   :1.0000   Max.   :1.0000  \n",
              " length_of_stay   \n",
              " Min.   :  1.071  \n",
              " 1st Qu.: 11.494  \n",
              " Median : 19.367  \n",
              " Mean   : 26.008  \n",
              " 3rd Qu.: 32.103  \n",
              " Max.   :172.646  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Specification\n",
        "model_code <- \"\n",
        "data {\n",
        "  int<lower=0> N;\n",
        "  vector[N] age_z;\n",
        "  int<lower=0, upper=1> male[N];\n",
        "  int<lower=0, upper=1> intervention[N];\n",
        "  vector[N] length_of_stay;\n",
        "}\n",
        "parameters {\n",
        "  real beta0;\n",
        "  real beta1;\n",
        "  real beta2;\n",
        "  real delta;\n",
        "  real<lower=0> sigma;\n",
        "}\n",
        "model {\n",
        "  beta0 ~ normal(0, 1);\n",
        "  beta1 ~ normal(0, 1);\n",
        "  beta2 ~ normal(0, 1);\n",
        "  delta ~ normal(0, 1);\n",
        "  sigma ~ cauchy(0, 1);\n",
        "\n",
        "  for (i in 1:N) {\n",
        "    length_of_stay[i] ~ normal(beta0 + beta1 * age_z[i] + beta2 * male[i] + delta * intervention[i], sigma);\n",
        "  }\n",
        "}\n",
        "\"\n"
      ],
      "metadata": {
        "id": "XEZTCunV5797"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for Stan\n",
        "stan_data <- list(\n",
        "  N = nrow(hospital_data),\n",
        "  age_z = hospital_data$age_z,\n",
        "  male = hospital_data$sex,\n",
        "  intervention = hospital_data$intervention,\n",
        "  length_of_stay = hospital_data$length_of_stay\n",
        ")\n"
      ],
      "metadata": {
        "id": "KM4-5WLs5_su"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bayesian estimation\n",
        "stan_model <- stan_model(model_code = model_code)\n",
        "stan_fit <- sampling(stan_model, data = stan_data, chains = 4, iter = 1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC55NOLI6pfL",
        "outputId": "e67827d5-f915-4df7-88bc-17a4b5314540"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\n",
            "Chain 1: \n",
            "Chain 1: Gradient evaluation took 0.000609 seconds\n",
            "Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 6.09 seconds.\n",
            "Chain 1: Adjust your expectations accordingly!\n",
            "Chain 1: \n",
            "Chain 1: \n",
            "Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup)\n",
            "Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
            "Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
            "Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
            "Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
            "Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
            "Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
            "Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
            "Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
            "Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
            "Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
            "Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling)\n",
            "Chain 1: \n",
            "Chain 1:  Elapsed Time: 2.584 seconds (Warm-up)\n",
            "Chain 1:                0.879 seconds (Sampling)\n",
            "Chain 1:                3.463 seconds (Total)\n",
            "Chain 1: \n",
            "\n",
            "SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\n",
            "Chain 2: \n",
            "Chain 2: Gradient evaluation took 0.000269 seconds\n",
            "Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 2.69 seconds.\n",
            "Chain 2: Adjust your expectations accordingly!\n",
            "Chain 2: \n",
            "Chain 2: \n",
            "Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup)\n",
            "Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
            "Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
            "Chain 2: Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
            "Chain 2: Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
            "Chain 2: Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
            "Chain 2: Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
            "Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
            "Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
            "Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
            "Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
            "Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling)\n",
            "Chain 2: \n",
            "Chain 2:  Elapsed Time: 2.569 seconds (Warm-up)\n",
            "Chain 2:                0.898 seconds (Sampling)\n",
            "Chain 2:                3.467 seconds (Total)\n",
            "Chain 2: \n",
            "\n",
            "SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\n",
            "Chain 3: \n",
            "Chain 3: Gradient evaluation took 0.000291 seconds\n",
            "Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 2.91 seconds.\n",
            "Chain 3: Adjust your expectations accordingly!\n",
            "Chain 3: \n",
            "Chain 3: \n",
            "Chain 3: Iteration:   1 / 1000 [  0%]  (Warmup)\n",
            "Chain 3: Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
            "Chain 3: Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
            "Chain 3: Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
            "Chain 3: Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
            "Chain 3: Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
            "Chain 3: Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
            "Chain 3: Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
            "Chain 3: Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
            "Chain 3: Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
            "Chain 3: Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
            "Chain 3: Iteration: 1000 / 1000 [100%]  (Sampling)\n",
            "Chain 3: \n",
            "Chain 3:  Elapsed Time: 2.731 seconds (Warm-up)\n",
            "Chain 3:                1.017 seconds (Sampling)\n",
            "Chain 3:                3.748 seconds (Total)\n",
            "Chain 3: \n",
            "\n",
            "SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\n",
            "Chain 4: \n",
            "Chain 4: Gradient evaluation took 0.000382 seconds\n",
            "Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 3.82 seconds.\n",
            "Chain 4: Adjust your expectations accordingly!\n",
            "Chain 4: \n",
            "Chain 4: \n",
            "Chain 4: Iteration:   1 / 1000 [  0%]  (Warmup)\n",
            "Chain 4: Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
            "Chain 4: Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
            "Chain 4: Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
            "Chain 4: Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
            "Chain 4: Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
            "Chain 4: Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
            "Chain 4: Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
            "Chain 4: Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
            "Chain 4: Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
            "Chain 4: Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
            "Chain 4: Iteration: 1000 / 1000 [100%]  (Sampling)\n",
            "Chain 4: \n",
            "Chain 4:  Elapsed Time: 3.654 seconds (Warm-up)\n",
            "Chain 4:                0.811 seconds (Sampling)\n",
            "Chain 4:                4.465 seconds (Total)\n",
            "Chain 4: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MCMC Diagnostics\n",
        "print(stan_fit)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gq1dT_u6tRf",
        "outputId": "e6e6fcaf-d2dc-4e9c-9b82-410526803357"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference for Stan model: anon_model.\n",
            "4 chains, each with iter=1000; warmup=500; thin=1; \n",
            "post-warmup draws per chain=500, total post-warmup draws=2000.\n",
            "\n",
            "          mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff\n",
            "beta0    10.24    0.02 0.90     8.42     9.65    10.25    10.85    11.97  2004\n",
            "beta1     2.51    0.02 0.76     1.04     2.00     2.51     3.01     4.00  2375\n",
            "beta2     4.25    0.02 0.87     2.61     3.66     4.22     4.82     5.93  2441\n",
            "delta     2.26    0.02 0.89     0.51     1.65     2.27     2.88     3.98  2495\n",
            "sigma    26.77    0.02 0.94    24.94    26.13    26.75    27.40    28.63  2020\n",
            "lp__  -2218.94    0.05 1.58 -2222.89 -2219.76 -2218.66 -2217.75 -2216.79   832\n",
            "      Rhat\n",
            "beta0    1\n",
            "beta1    1\n",
            "beta2    1\n",
            "delta    1\n",
            "sigma    1\n",
            "lp__     1\n",
            "\n",
            "Samples were drawn using NUTS(diag_e) at Sun Jan 28 12:11:42 2024.\n",
            "For each parameter, n_eff is a crude measure of effective sample size,\n",
            "and Rhat is the potential scale reduction factor on split chains (at \n",
            "convergence, Rhat=1).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Parameter Estimates\n",
        "summary(stan_fit)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "kboW2Bmo6vrI",
        "outputId": "0ffa1605-b791-4ae2-ac56-c59ff588a2c1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$summary</dt>\n",
              "\t\t<dd><table class=\"dataframe\">\n",
              "<caption>A matrix: 6 × 10 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>mean</th><th scope=col>se_mean</th><th scope=col>sd</th><th scope=col>2.5%</th><th scope=col>25%</th><th scope=col>50%</th><th scope=col>75%</th><th scope=col>97.5%</th><th scope=col>n_eff</th><th scope=col>Rhat</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>beta0</th><td>   10.235222</td><td>0.02015633</td><td>0.9022194</td><td>    8.4244386</td><td>    9.647820</td><td>   10.252732</td><td>   10.850728</td><td>   11.968107</td><td>2003.556</td><td>1.0018286</td></tr>\n",
              "\t<tr><th scope=row>beta1</th><td>    2.511851</td><td>0.01549277</td><td>0.7550406</td><td>    1.0385291</td><td>    1.997228</td><td>    2.508532</td><td>    3.008662</td><td>    4.000576</td><td>2375.103</td><td>1.0007874</td></tr>\n",
              "\t<tr><th scope=row>beta2</th><td>    4.245888</td><td>0.01758689</td><td>0.8689105</td><td>    2.6119714</td><td>    3.660297</td><td>    4.220993</td><td>    4.817763</td><td>    5.925929</td><td>2441.023</td><td>1.0017301</td></tr>\n",
              "\t<tr><th scope=row>delta</th><td>    2.258573</td><td>0.01790077</td><td>0.8941934</td><td>    0.5059178</td><td>    1.652743</td><td>    2.265484</td><td>    2.883105</td><td>    3.982564</td><td>2495.281</td><td>0.9989951</td></tr>\n",
              "\t<tr><th scope=row>sigma</th><td>   26.766514</td><td>0.02096039</td><td>0.9420139</td><td>   24.9446340</td><td>   26.130370</td><td>   26.750633</td><td>   27.398413</td><td>   28.633035</td><td>2019.835</td><td>1.0003281</td></tr>\n",
              "\t<tr><th scope=row>lp__</th><td>-2218.941586</td><td>0.05479138</td><td>1.5802399</td><td>-2222.8876106</td><td>-2219.760089</td><td>-2218.657112</td><td>-2217.749868</td><td>-2216.793466</td><td> 831.805</td><td>1.0004630</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</dd>\n",
              "\t<dt>$c_summary</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>10.2176478782993</li><li>2.53783820694247</li><li>4.22035581574713</li><li>2.24123162139744</li><li>26.7323394148437</li><li>-2218.91953428166</li><li>0.916732255197482</li><li>0.743528098917926</li><li>0.912627229227884</li><li>0.882029010943847</li><li>0.908637229030813</li><li>1.49075620428989</li><li>8.42264936836627</li><li>1.08665868948667</li><li>2.46839716002216</li><li>0.501420485764076</li><li>24.9946234729541</li><li>-2222.5649354538</li><li>9.6347343548856</li><li>2.08020268134166</li><li>3.63350685637938</li><li>1.68294826671526</li><li>26.0942372267221</li><li>-2219.73070168157</li><li>10.2599397462147</li><li>2.54258172479919</li><li>4.17359305411243</li><li>2.24426071730474</li><li>26.7442837018624</li><li>-2218.63961276753</li><li>10.8386830543408</li><li>3.01008824269577</li><li>4.78446755902768</li><li>2.83672904849899</li><li>27.3216006323908</li><li>-2217.78943137051</li><li>12.0181124128104</li><li>3.99477441974582</li><li>6.01369165452791</li><li>3.91748007489958</li><li>28.6647004132176</li><li>-2216.84752186434</li><li>10.1820274690201</li><li>2.48563822903237</li><li>4.20149972645206</li><li>2.26266760922854</li><li>26.7827373107763</li><li>-2218.9125191947</li><li>0.940566854543932</li><li>0.693040075809486</li><li>0.822144041269301</li><li>0.872843972003942</li><li>1.01585538974217</li><li>1.50413360087619</li><li>8.38560329120894</li><li>1.11094047853292</li><li>2.66316201469416</li><li>0.584447415011067</li><li>24.9021814655959</li><li>-2222.44535356553</li><li>9.57021612228152</li><li>2.00300300154569</li><li>3.64379480129351</li><li>1.61470310345477</li><li>26.0646530308062</li><li>-2219.6696272666</li><li>10.1554619900345</li><li>2.47020558989527</li><li>4.17868911264266</li><li>2.30890645334583</li><li>26.7407057947278</li><li>-2218.7441296266</li><li>10.8084352927662</li><li>2.95170616493051</li><li>4.76922996994834</li><li>2.92188820775049</li><li>27.4561156027822</li><li>-2217.73579682111</li><li>12.0407266312936</li><li>3.88888472030844</li><li>5.81365616617729</li><li>3.91669194357624</li><li>28.6889461558639</li><li>-2216.80949023572</li><li>10.2236460673808</li><li>2.5174814186111</li><li>4.33153122648736</li><li>2.26435252733338</li><li>26.7874197314444</li><li>-2218.88180200523</li><li>0.87801745731471</li><li>0.755839347386294</li><li>0.86841764989981</li><li>0.9038988557485</li><li>0.917116536390384</li><li>1.60456057089001</li><li>8.44052551311936</li><li>0.963781990652498</li><li>2.60608258008353</li><li>0.523979311748261</li><li>25.0217404323931</li><li>-2223.14628673896</li><li>9.65795181449589</li><li>2.02613444652972</li><li>3.73318112397171</li><li>1.65910135169721</li><li>26.175329988104</li><li>-2219.61741666942</li><li>10.2638120045329</li><li>2.51645733191345</li><li>4.34016092845244</li><li>2.23668244205123</li><li>26.8084247196665</li><li>-2218.53844724265</li><li>10.8117165316431</li><li>3.01190141544655</li><li>4.90678891579356</li><li>2.91876200711237</li><li>27.4172272348812</li><li>-2217.7167941642</li><li>11.9048718731439</li><li>3.94026216700819</li><li>5.87967161633268</li><li>4.08451613269044</li><li>28.4793761796972</li><li>-2216.77192575635</li><li>10.3175679226368</li><li>2.50644766354646</li><li>4.23016429395509</li><li>2.26603878726847</li><li>26.7635606702755</li><li>-2219.05248989307</li><li>0.86881579287465</li><li>0.823355896388857</li><li>0.866820333181835</li><li>0.919707530224809</li><li>0.92429911728049</li><li>1.71085361906143</li><li>8.49534154623113</li><li>1.00391217737134</li><li>2.72211892848559</li><li>0.469338672326539</li><li>24.9298549908446</li><li>-2223.63911951042</li><li>9.74691087969279</li><li>1.92360002706786</li><li>3.61683104555602</li><li>1.6758939102133</li><li>26.1306048989127</li><li>-2220.07396287359</li><li>10.3195958514348</li><li>2.48930786033611</li><li>4.18335130598511</li><li>2.27273284295001</li><li>26.7362769067584</li><li>-2218.66806070162</li><li>10.9140967677474</li><li>3.06939593497428</li><li>4.83655859685599</li><li>2.85206170075608</li><li>27.3827621049087</li><li>-2217.78652977429</li><li>11.9835191098856</li><li>4.13318738346652</li><li>5.89214635094123</li><li>4.06492500671868</li><li>28.6269252124961</li><li>-2216.7479025201</li></ol>\n",
              "</dd>\n",
              "</dl>\n"
            ],
            "text/markdown": "$summary\n:   \nA matrix: 6 × 10 of type dbl\n\n| <!--/--> | mean | se_mean | sd | 2.5% | 25% | 50% | 75% | 97.5% | n_eff | Rhat |\n|---|---|---|---|---|---|---|---|---|---|---|\n| beta0 |    10.235222 | 0.02015633 | 0.9022194 |     8.4244386 |     9.647820 |    10.252732 |    10.850728 |    11.968107 | 2003.556 | 1.0018286 |\n| beta1 |     2.511851 | 0.01549277 | 0.7550406 |     1.0385291 |     1.997228 |     2.508532 |     3.008662 |     4.000576 | 2375.103 | 1.0007874 |\n| beta2 |     4.245888 | 0.01758689 | 0.8689105 |     2.6119714 |     3.660297 |     4.220993 |     4.817763 |     5.925929 | 2441.023 | 1.0017301 |\n| delta |     2.258573 | 0.01790077 | 0.8941934 |     0.5059178 |     1.652743 |     2.265484 |     2.883105 |     3.982564 | 2495.281 | 0.9989951 |\n| sigma |    26.766514 | 0.02096039 | 0.9420139 |    24.9446340 |    26.130370 |    26.750633 |    27.398413 |    28.633035 | 2019.835 | 1.0003281 |\n| lp__ | -2218.941586 | 0.05479138 | 1.5802399 | -2222.8876106 | -2219.760089 | -2218.657112 | -2217.749868 | -2216.793466 |  831.805 | 1.0004630 |\n\n\n$c_summary\n:   1. 10.2176478782993\n2. 2.53783820694247\n3. 4.22035581574713\n4. 2.24123162139744\n5. 26.7323394148437\n6. -2218.91953428166\n7. 0.916732255197482\n8. 0.743528098917926\n9. 0.912627229227884\n10. 0.882029010943847\n11. 0.908637229030813\n12. 1.49075620428989\n13. 8.42264936836627\n14. 1.08665868948667\n15. 2.46839716002216\n16. 0.501420485764076\n17. 24.9946234729541\n18. -2222.5649354538\n19. 9.6347343548856\n20. 2.08020268134166\n21. 3.63350685637938\n22. 1.68294826671526\n23. 26.0942372267221\n24. -2219.73070168157\n25. 10.2599397462147\n26. 2.54258172479919\n27. 4.17359305411243\n28. 2.24426071730474\n29. 26.7442837018624\n30. -2218.63961276753\n31. 10.8386830543408\n32. 3.01008824269577\n33. 4.78446755902768\n34. 2.83672904849899\n35. 27.3216006323908\n36. -2217.78943137051\n37. 12.0181124128104\n38. 3.99477441974582\n39. 6.01369165452791\n40. 3.91748007489958\n41. 28.6647004132176\n42. -2216.84752186434\n43. 10.1820274690201\n44. 2.48563822903237\n45. 4.20149972645206\n46. 2.26266760922854\n47. 26.7827373107763\n48. -2218.9125191947\n49. 0.940566854543932\n50. 0.693040075809486\n51. 0.822144041269301\n52. 0.872843972003942\n53. 1.01585538974217\n54. 1.50413360087619\n55. 8.38560329120894\n56. 1.11094047853292\n57. 2.66316201469416\n58. 0.584447415011067\n59. 24.9021814655959\n60. -2222.44535356553\n61. 9.57021612228152\n62. 2.00300300154569\n63. 3.64379480129351\n64. 1.61470310345477\n65. 26.0646530308062\n66. -2219.6696272666\n67. 10.1554619900345\n68. 2.47020558989527\n69. 4.17868911264266\n70. 2.30890645334583\n71. 26.7407057947278\n72. -2218.7441296266\n73. 10.8084352927662\n74. 2.95170616493051\n75. 4.76922996994834\n76. 2.92188820775049\n77. 27.4561156027822\n78. -2217.73579682111\n79. 12.0407266312936\n80. 3.88888472030844\n81. 5.81365616617729\n82. 3.91669194357624\n83. 28.6889461558639\n84. -2216.80949023572\n85. 10.2236460673808\n86. 2.5174814186111\n87. 4.33153122648736\n88. 2.26435252733338\n89. 26.7874197314444\n90. -2218.88180200523\n91. 0.87801745731471\n92. 0.755839347386294\n93. 0.86841764989981\n94. 0.9038988557485\n95. 0.917116536390384\n96. 1.60456057089001\n97. 8.44052551311936\n98. 0.963781990652498\n99. 2.60608258008353\n100. 0.523979311748261\n101. 25.0217404323931\n102. -2223.14628673896\n103. 9.65795181449589\n104. 2.02613444652972\n105. 3.73318112397171\n106. 1.65910135169721\n107. 26.175329988104\n108. -2219.61741666942\n109. 10.2638120045329\n110. 2.51645733191345\n111. 4.34016092845244\n112. 2.23668244205123\n113. 26.8084247196665\n114. -2218.53844724265\n115. 10.8117165316431\n116. 3.01190141544655\n117. 4.90678891579356\n118. 2.91876200711237\n119. 27.4172272348812\n120. -2217.7167941642\n121. 11.9048718731439\n122. 3.94026216700819\n123. 5.87967161633268\n124. 4.08451613269044\n125. 28.4793761796972\n126. -2216.77192575635\n127. 10.3175679226368\n128. 2.50644766354646\n129. 4.23016429395509\n130. 2.26603878726847\n131. 26.7635606702755\n132. -2219.05248989307\n133. 0.86881579287465\n134. 0.823355896388857\n135. 0.866820333181835\n136. 0.919707530224809\n137. 0.92429911728049\n138. 1.71085361906143\n139. 8.49534154623113\n140. 1.00391217737134\n141. 2.72211892848559\n142. 0.469338672326539\n143. 24.9298549908446\n144. -2223.63911951042\n145. 9.74691087969279\n146. 1.92360002706786\n147. 3.61683104555602\n148. 1.6758939102133\n149. 26.1306048989127\n150. -2220.07396287359\n151. 10.3195958514348\n152. 2.48930786033611\n153. 4.18335130598511\n154. 2.27273284295001\n155. 26.7362769067584\n156. -2218.66806070162\n157. 10.9140967677474\n158. 3.06939593497428\n159. 4.83655859685599\n160. 2.85206170075608\n161. 27.3827621049087\n162. -2217.78652977429\n163. 11.9835191098856\n164. 4.13318738346652\n165. 5.89214635094123\n166. 4.06492500671868\n167. 28.6269252124961\n168. -2216.7479025201\n\n\n\n\n\n",
            "text/latex": "\\begin{description}\n\\item[\\$summary] A matrix: 6 × 10 of type dbl\n\\begin{tabular}{r|llllllllll}\n  & mean & se\\_mean & sd & 2.5\\% & 25\\% & 50\\% & 75\\% & 97.5\\% & n\\_eff & Rhat\\\\\n\\hline\n\tbeta0 &    10.235222 & 0.02015633 & 0.9022194 &     8.4244386 &     9.647820 &    10.252732 &    10.850728 &    11.968107 & 2003.556 & 1.0018286\\\\\n\tbeta1 &     2.511851 & 0.01549277 & 0.7550406 &     1.0385291 &     1.997228 &     2.508532 &     3.008662 &     4.000576 & 2375.103 & 1.0007874\\\\\n\tbeta2 &     4.245888 & 0.01758689 & 0.8689105 &     2.6119714 &     3.660297 &     4.220993 &     4.817763 &     5.925929 & 2441.023 & 1.0017301\\\\\n\tdelta &     2.258573 & 0.01790077 & 0.8941934 &     0.5059178 &     1.652743 &     2.265484 &     2.883105 &     3.982564 & 2495.281 & 0.9989951\\\\\n\tsigma &    26.766514 & 0.02096039 & 0.9420139 &    24.9446340 &    26.130370 &    26.750633 &    27.398413 &    28.633035 & 2019.835 & 1.0003281\\\\\n\tlp\\_\\_ & -2218.941586 & 0.05479138 & 1.5802399 & -2222.8876106 & -2219.760089 & -2218.657112 & -2217.749868 & -2216.793466 &  831.805 & 1.0004630\\\\\n\\end{tabular}\n\n\\item[\\$c\\_summary] \\begin{enumerate*}\n\\item 10.2176478782993\n\\item 2.53783820694247\n\\item 4.22035581574713\n\\item 2.24123162139744\n\\item 26.7323394148437\n\\item -2218.91953428166\n\\item 0.916732255197482\n\\item 0.743528098917926\n\\item 0.912627229227884\n\\item 0.882029010943847\n\\item 0.908637229030813\n\\item 1.49075620428989\n\\item 8.42264936836627\n\\item 1.08665868948667\n\\item 2.46839716002216\n\\item 0.501420485764076\n\\item 24.9946234729541\n\\item -2222.5649354538\n\\item 9.6347343548856\n\\item 2.08020268134166\n\\item 3.63350685637938\n\\item 1.68294826671526\n\\item 26.0942372267221\n\\item -2219.73070168157\n\\item 10.2599397462147\n\\item 2.54258172479919\n\\item 4.17359305411243\n\\item 2.24426071730474\n\\item 26.7442837018624\n\\item -2218.63961276753\n\\item 10.8386830543408\n\\item 3.01008824269577\n\\item 4.78446755902768\n\\item 2.83672904849899\n\\item 27.3216006323908\n\\item -2217.78943137051\n\\item 12.0181124128104\n\\item 3.99477441974582\n\\item 6.01369165452791\n\\item 3.91748007489958\n\\item 28.6647004132176\n\\item -2216.84752186434\n\\item 10.1820274690201\n\\item 2.48563822903237\n\\item 4.20149972645206\n\\item 2.26266760922854\n\\item 26.7827373107763\n\\item -2218.9125191947\n\\item 0.940566854543932\n\\item 0.693040075809486\n\\item 0.822144041269301\n\\item 0.872843972003942\n\\item 1.01585538974217\n\\item 1.50413360087619\n\\item 8.38560329120894\n\\item 1.11094047853292\n\\item 2.66316201469416\n\\item 0.584447415011067\n\\item 24.9021814655959\n\\item -2222.44535356553\n\\item 9.57021612228152\n\\item 2.00300300154569\n\\item 3.64379480129351\n\\item 1.61470310345477\n\\item 26.0646530308062\n\\item -2219.6696272666\n\\item 10.1554619900345\n\\item 2.47020558989527\n\\item 4.17868911264266\n\\item 2.30890645334583\n\\item 26.7407057947278\n\\item -2218.7441296266\n\\item 10.8084352927662\n\\item 2.95170616493051\n\\item 4.76922996994834\n\\item 2.92188820775049\n\\item 27.4561156027822\n\\item -2217.73579682111\n\\item 12.0407266312936\n\\item 3.88888472030844\n\\item 5.81365616617729\n\\item 3.91669194357624\n\\item 28.6889461558639\n\\item -2216.80949023572\n\\item 10.2236460673808\n\\item 2.5174814186111\n\\item 4.33153122648736\n\\item 2.26435252733338\n\\item 26.7874197314444\n\\item -2218.88180200523\n\\item 0.87801745731471\n\\item 0.755839347386294\n\\item 0.86841764989981\n\\item 0.9038988557485\n\\item 0.917116536390384\n\\item 1.60456057089001\n\\item 8.44052551311936\n\\item 0.963781990652498\n\\item 2.60608258008353\n\\item 0.523979311748261\n\\item 25.0217404323931\n\\item -2223.14628673896\n\\item 9.65795181449589\n\\item 2.02613444652972\n\\item 3.73318112397171\n\\item 1.65910135169721\n\\item 26.175329988104\n\\item -2219.61741666942\n\\item 10.2638120045329\n\\item 2.51645733191345\n\\item 4.34016092845244\n\\item 2.23668244205123\n\\item 26.8084247196665\n\\item -2218.53844724265\n\\item 10.8117165316431\n\\item 3.01190141544655\n\\item 4.90678891579356\n\\item 2.91876200711237\n\\item 27.4172272348812\n\\item -2217.7167941642\n\\item 11.9048718731439\n\\item 3.94026216700819\n\\item 5.87967161633268\n\\item 4.08451613269044\n\\item 28.4793761796972\n\\item -2216.77192575635\n\\item 10.3175679226368\n\\item 2.50644766354646\n\\item 4.23016429395509\n\\item 2.26603878726847\n\\item 26.7635606702755\n\\item -2219.05248989307\n\\item 0.86881579287465\n\\item 0.823355896388857\n\\item 0.866820333181835\n\\item 0.919707530224809\n\\item 0.92429911728049\n\\item 1.71085361906143\n\\item 8.49534154623113\n\\item 1.00391217737134\n\\item 2.72211892848559\n\\item 0.469338672326539\n\\item 24.9298549908446\n\\item -2223.63911951042\n\\item 9.74691087969279\n\\item 1.92360002706786\n\\item 3.61683104555602\n\\item 1.6758939102133\n\\item 26.1306048989127\n\\item -2220.07396287359\n\\item 10.3195958514348\n\\item 2.48930786033611\n\\item 4.18335130598511\n\\item 2.27273284295001\n\\item 26.7362769067584\n\\item -2218.66806070162\n\\item 10.9140967677474\n\\item 3.06939593497428\n\\item 4.83655859685599\n\\item 2.85206170075608\n\\item 27.3827621049087\n\\item -2217.78652977429\n\\item 11.9835191098856\n\\item 4.13318738346652\n\\item 5.89214635094123\n\\item 4.06492500671868\n\\item 28.6269252124961\n\\item -2216.7479025201\n\\end{enumerate*}\n\n\\end{description}\n",
            "text/plain": [
              "$summary\n",
              "              mean    se_mean        sd          2.5%          25%          50%\n",
              "beta0    10.235222 0.02015633 0.9022194     8.4244386     9.647820    10.252732\n",
              "beta1     2.511851 0.01549277 0.7550406     1.0385291     1.997228     2.508532\n",
              "beta2     4.245888 0.01758689 0.8689105     2.6119714     3.660297     4.220993\n",
              "delta     2.258573 0.01790077 0.8941934     0.5059178     1.652743     2.265484\n",
              "sigma    26.766514 0.02096039 0.9420139    24.9446340    26.130370    26.750633\n",
              "lp__  -2218.941586 0.05479138 1.5802399 -2222.8876106 -2219.760089 -2218.657112\n",
              "               75%        97.5%    n_eff      Rhat\n",
              "beta0    10.850728    11.968107 2003.556 1.0018286\n",
              "beta1     3.008662     4.000576 2375.103 1.0007874\n",
              "beta2     4.817763     5.925929 2441.023 1.0017301\n",
              "delta     2.883105     3.982564 2495.281 0.9989951\n",
              "sigma    27.398413    28.633035 2019.835 1.0003281\n",
              "lp__  -2217.749868 -2216.793466  831.805 1.0004630\n",
              "\n",
              "$c_summary\n",
              ", , chains = chain:1\n",
              "\n",
              "         stats\n",
              "parameter         mean        sd          2.5%          25%          50%\n",
              "    beta0    10.217648 0.9167323     8.4226494     9.634734    10.259940\n",
              "    beta1     2.537838 0.7435281     1.0866587     2.080203     2.542582\n",
              "    beta2     4.220356 0.9126272     2.4683972     3.633507     4.173593\n",
              "    delta     2.241232 0.8820290     0.5014205     1.682948     2.244261\n",
              "    sigma    26.732339 0.9086372    24.9946235    26.094237    26.744284\n",
              "    lp__  -2218.919534 1.4907562 -2222.5649355 -2219.730702 -2218.639613\n",
              "         stats\n",
              "parameter          75%        97.5%\n",
              "    beta0    10.838683    12.018112\n",
              "    beta1     3.010088     3.994774\n",
              "    beta2     4.784468     6.013692\n",
              "    delta     2.836729     3.917480\n",
              "    sigma    27.321601    28.664700\n",
              "    lp__  -2217.789431 -2216.847522\n",
              "\n",
              ", , chains = chain:2\n",
              "\n",
              "         stats\n",
              "parameter         mean        sd          2.5%          25%          50%\n",
              "    beta0    10.182027 0.9405669     8.3856033     9.570216    10.155462\n",
              "    beta1     2.485638 0.6930401     1.1109405     2.003003     2.470206\n",
              "    beta2     4.201500 0.8221440     2.6631620     3.643795     4.178689\n",
              "    delta     2.262668 0.8728440     0.5844474     1.614703     2.308906\n",
              "    sigma    26.782737 1.0158554    24.9021815    26.064653    26.740706\n",
              "    lp__  -2218.912519 1.5041336 -2222.4453536 -2219.669627 -2218.744130\n",
              "         stats\n",
              "parameter          75%        97.5%\n",
              "    beta0    10.808435    12.040727\n",
              "    beta1     2.951706     3.888885\n",
              "    beta2     4.769230     5.813656\n",
              "    delta     2.921888     3.916692\n",
              "    sigma    27.456116    28.688946\n",
              "    lp__  -2217.735797 -2216.809490\n",
              "\n",
              ", , chains = chain:3\n",
              "\n",
              "         stats\n",
              "parameter         mean        sd          2.5%          25%          50%\n",
              "    beta0    10.223646 0.8780175     8.4405255     9.657952    10.263812\n",
              "    beta1     2.517481 0.7558393     0.9637820     2.026134     2.516457\n",
              "    beta2     4.331531 0.8684176     2.6060826     3.733181     4.340161\n",
              "    delta     2.264353 0.9038989     0.5239793     1.659101     2.236682\n",
              "    sigma    26.787420 0.9171165    25.0217404    26.175330    26.808425\n",
              "    lp__  -2218.881802 1.6045606 -2223.1462867 -2219.617417 -2218.538447\n",
              "         stats\n",
              "parameter          75%        97.5%\n",
              "    beta0    10.811717    11.904872\n",
              "    beta1     3.011901     3.940262\n",
              "    beta2     4.906789     5.879672\n",
              "    delta     2.918762     4.084516\n",
              "    sigma    27.417227    28.479376\n",
              "    lp__  -2217.716794 -2216.771926\n",
              "\n",
              ", , chains = chain:4\n",
              "\n",
              "         stats\n",
              "parameter         mean        sd          2.5%          25%          50%\n",
              "    beta0    10.317568 0.8688158     8.4953415     9.746911    10.319596\n",
              "    beta1     2.506448 0.8233559     1.0039122     1.923600     2.489308\n",
              "    beta2     4.230164 0.8668203     2.7221189     3.616831     4.183351\n",
              "    delta     2.266039 0.9197075     0.4693387     1.675894     2.272733\n",
              "    sigma    26.763561 0.9242991    24.9298550    26.130605    26.736277\n",
              "    lp__  -2219.052490 1.7108536 -2223.6391195 -2220.073963 -2218.668061\n",
              "         stats\n",
              "parameter          75%        97.5%\n",
              "    beta0    10.914097    11.983519\n",
              "    beta1     3.069396     4.133187\n",
              "    beta2     4.836559     5.892146\n",
              "    delta     2.852062     4.064925\n",
              "    sigma    27.382762    28.626925\n",
              "    lp__  -2217.786530 -2216.747903\n",
              "\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate per-patient net costs\n",
        "cost_per_bed_day <- 350\n",
        "per_patient_program_cost <- 20000\n",
        "posterior_samples <- as.data.frame(stan_fit)\n",
        "mean_difference <- mean(posterior_samples$sigma)\n",
        "\n",
        "probability_cost_saving <- pnorm(0, mean_difference * cost_per_bed_day - per_patient_program_cost, sd(posterior_samples$sigma))\n",
        "probability_cost_saving\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "dsB9-LtS6tP0",
        "outputId": "b4491daa-e7a9-43d5-cf97-efa486329735"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1"
            ],
            "text/markdown": "1",
            "text/latex": "1",
            "text/plain": [
              "[1] 1"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}