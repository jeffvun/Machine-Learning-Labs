{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMCDKz9OY6UQzWo4oRVCcH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffvun/Machine-Learning-Labs/blob/main/Image_Forensics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Libraries**"
      ],
      "metadata": {
        "id": "onzUtpsW49Gc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLEkkKZW4y7b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import FasterRCNN, ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.models import Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Preprocessing**"
      ],
      "metadata": {
        "id": "au3M3fB15HIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your data directories\n",
        "data_dir = '/Content/data'\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "# Image data generator for data augmentation\n",
        "datagen = ImageDataGenerator(rescale=1./255,\n",
        "                             shear_range=0.2,\n",
        "                             zoom_range=0.2,\n",
        "                             horizontal_flip=True)\n",
        "\n",
        "# Create generators for training and testing data\n",
        "batch_size = 32\n",
        "train_generator = datagen.flow_from_directory(train_dir,\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=batch_size,\n",
        "                                              class_mode='binary')\n",
        "\n",
        "test_generator = datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=(224, 224),\n",
        "                                             batch_size=batch_size,\n",
        "                                             class_mode='binary')\n"
      ],
      "metadata": {
        "id": "tx3qJPvR5Ku3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Product Identification using R-CNN**"
      ],
      "metadata": {
        "id": "bzA29IvL5XMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pre-trained ResNet50 as the base model for Faster R-CNN\n",
        "base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_frcnn = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model_frcnn.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_frcnn.fit(train_generator, epochs=5, validation_data=test_generator)\n"
      ],
      "metadata": {
        "id": "JQsQLl0X5dqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Image Classification using GAN model***"
      ],
      "metadata": {
        "id": "6cf6A5Zi6vRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **import necessary libraries**"
      ],
      "metadata": {
        "id": "L39TuLpt7MSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "cgTWK3D264cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Define GAN architecture for image classification**"
      ],
      "metadata": {
        "id": "qdSMxpdx8g1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_gan(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    gan_input = Input(shape=(100,))\n",
        "    x = generator(gan_input)\n",
        "    gan_output = discriminator(x)\n",
        "    gan = Model(gan_input, gan_output)\n",
        "    gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "    return gan\n"
      ],
      "metadata": {
        "id": "vcwlaU6W8n_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Define a simple generator**"
      ],
      "metadata": {
        "id": "3mtGGx5Y85li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(latent_dim, output_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(np.prod(output_shape), activation='sigmoid'))\n",
        "    model.add(Reshape(output_shape))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "_blcbSDA9AQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Define a simple discriminator**"
      ],
      "metadata": {
        "id": "5DnHkUpU9PUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=input_shape))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "JVfD5c539WPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Build and compile the generator and discriminator**"
      ],
      "metadata": {
        "id": "QcK2x09x90Uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 100\n",
        "img_shape = (64, 64, 3)\n",
        "\n",
        "generator = build_generator(latent_dim, img_shape)\n",
        "discriminator = build_discriminator(img_shape)\n",
        "gan = build_gan(generator, discriminator)\n"
      ],
      "metadata": {
        "id": "yFVO7Kr_97wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train the GAN**"
      ],
      "metadata": {
        "id": "ZAl233HYFpMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "dataset = train_generator\n",
        "\n",
        "def train_gan(dataset, gan, epochs=10, batch_size=32, latent_dim=100):\n",
        "    half_batch = batch_size // 2\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Train discriminator\n",
        "        for _ in tqdm(range(len(dataset)//batch_size), desc=f\"Epoch {epoch+1}/{epochs} - Discriminator\"):\n",
        "            real_images, _ = dataset.next()\n",
        "            noise = np.random.normal(0, 1, (half_batch, latent_dim))\n",
        "            generated_images = gan.generator.predict(noise)\n",
        "\n",
        "            real_labels = np.ones((half_batch, 1))\n",
        "            fake_labels = np.zeros((half_batch, 1))\n",
        "\n",
        "            d_loss_real = gan.discriminator.train_on_batch(real_images, real_labels)\n",
        "            d_loss_fake = gan.discriminator.train_on_batch(generated_images, fake_labels)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # Train generator\n",
        "        for _ in tqdm(range(len(dataset)//batch_size), desc=f\"Epoch {epoch+1}/{epochs} - Generator\"):\n",
        "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "            valid_labels = np.ones((batch_size, 1))\n",
        "\n",
        "            g_loss = gan.combined.train_on_batch(noise, valid_labels)\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{epochs} [D loss: {d_loss[0]} | D accuracy: {100 * d_loss[1]}] [G loss: {g_loss}]\")\n"
      ],
      "metadata": {
        "id": "4jgD-ZleFP7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Extract features from the trained GAN model**"
      ],
      "metadata": {
        "id": "otKW9XfrFOfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_gan_features(generator, data_generator, num_samples=1000):\n",
        "    features = []\n",
        "    for _ in range(num_samples):\n",
        "        batch, _ = data_generator.next()\n",
        "        generated_images = generator.predict(np.random.normal(0, 1, (batch_size, latent_dim)))\n",
        "        features.extend(generated_images)\n",
        "    return np.array(features)"
      ],
      "metadata": {
        "id": "DpYCh0a0FMdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train the GAN model and extract features**"
      ],
      "metadata": {
        "id": "whn19qgPsfR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gan.fit()\n",
        "train_gan_features = extract_gan_features(generator, train_generator)\n",
        "test_gan_features = extract_gan_features(generator, test_generator)"
      ],
      "metadata": {
        "id": "DOUKnIRgsvAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Define a basic CNN classifier for image classification**"
      ],
      "metadata": {
        "id": "xM7-T9QAsvTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential()\n",
        "classifier.add(Conv2D(32, kernel_size=(3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(128, activation='relu'))\n",
        "classifier.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "NiJDLsyStQdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train the classifier**"
      ],
      "metadata": {
        "id": "3PIi7zgXtWc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit(train_gan_features, train_generator.classes, epochs=5, batch_size=batch_size, validation_data=(test_gan_features, test_generator.classes))"
      ],
      "metadata": {
        "id": "n6bTA_YHtdft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Save the trained GAN and classifier models**"
      ],
      "metadata": {
        "id": "OYAgXXc2td74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gan.save('gan_model.h5')\n",
        "classifier.save('classifier_model.h5')"
      ],
      "metadata": {
        "id": "9tm4GgqKtjkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Integration and Testing**"
      ],
      "metadata": {
        "id": "frViejR3twUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import necessary libraries**"
      ],
      "metadata": {
        "id": "fhvhhKK9t2I4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "import cv2\n",
        "\n",
        "loaded_gan = load_model('gan_model.h5')\n",
        "loaded_classifier = load_model('classifier_model.h5')"
      ],
      "metadata": {
        "id": "w5CqjdYNt53s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Product Identification**"
      ],
      "metadata": {
        "id": "ZTrqPhEkuLGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the trained Faster R-CNN model to identify products in an image"
      ],
      "metadata": {
        "id": "wxu8zKBKugwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform object detection using Faster R-CNN\n",
        "\n",
        "def detect_objects(image_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Perform object detection\n",
        "    results = model_frcnn.predict(np.expand_dims(image_rgb, axis=0))\n",
        "\n",
        "    # Extract bounding boxes and class labels\n",
        "    boxes = results['detection_boxes'][0].numpy()\n",
        "    scores = results['detection_scores'][0].numpy()\n",
        "    classes = results['detection_classes'][0].numpy().astype(np.int)\n",
        "\n",
        "    # Filter out low-confidence detections (adjust threshold as needed)\n",
        "    threshold = 0.5\n",
        "    selected_boxes = boxes[scores >= threshold]\n",
        "    selected_classes = classes[scores >= threshold]\n",
        "\n",
        "    return selected_boxes, selected_classes\n",
        "\n",
        "# Example usage:\n",
        "image_path = '/path/to/test/image.jpg'\n",
        "detected_boxes, detected_classes = detect_objects(image_path)\n"
      ],
      "metadata": {
        "id": "wO5rLDZoujge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Crop and preprocess the identified products**"
      ],
      "metadata": {
        "id": "ZPlsuOZgukMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_and_preprocess(image, boxes):\n",
        "    cropped_products = []\n",
        "    for box in boxes:\n",
        "        ymin, xmin, ymax, xmax = box\n",
        "        ymin, xmin, ymax, xmax = int(ymin * image.shape[0]), int(xmin * image.shape[1]), int(ymax * image.shape[0]), int(xmax * image.shape[1])\n",
        "\n",
        "        # Crop the product from the image\n",
        "        cropped_product = image[ymin:ymax, xmin:xmax]\n",
        "\n",
        "        # Resize the cropped product to the required input size for GAN\n",
        "        cropped_product = cv2.resize(cropped_product, (224, 224))\n",
        "\n",
        "        # Preprocess the image (adjust as needed)\n",
        "        cropped_product = cropped_product / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "        cropped_products.append(cropped_product)\n",
        "\n",
        "    return cropped_products\n",
        "\n",
        "# Example usage:\n",
        "cropped_products = crop_and_preprocess(cv2.imread(image_path), detected_boxes)\n"
      ],
      "metadata": {
        "id": "ogXh_d2HuruV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Binary Image Classification**"
      ],
      "metadata": {
        "id": "7Y2sRIOSus20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the GAN model to classify each product image as genuine or fake"
      ],
      "metadata": {
        "id": "APjnuNcLu0Dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now you can use the GAN and classifier models to classify each cropped product\n",
        "for product_image in cropped_products:\n",
        "    # Use the GAN model to classify each product image as genuine or fake\n",
        "    features = extract_gan_features(generator, np.expand_dims(product_image, axis=0))\n",
        "    classification = classifier.predict(features)\n",
        "\n",
        "    # Print the classification result (you may want to store or use this information as needed)\n",
        "    print(f'Product Classification: {classification}')"
      ],
      "metadata": {
        "id": "0WEkYIlHvKA0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}